{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd63292d",
   "metadata": {},
   "source": [
    "# Classification using Machine Learning Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0183d9da",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c280b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e28bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe with only the columns of the selected features\n",
    "import pandas as pd\n",
    "columns_to_keep= ['spectralFluxUV_sma3nz_amean', \n",
    "                  'shimmerLocaldB_sma3nz_stddevNorm',\n",
    "                  'HNRdBACF_sma3nz_amean',\n",
    "                  'shimmerLocaldB_sma3nz_amean',\n",
    "                  'HNRdBACF_sma3nz_stddevNorm',\n",
    "                  'slopeUV500-1500_sma3nz_amean',\n",
    "                  'F2frequency_sma3nz_stddevNorm',\n",
    "                  'loudness_sma3_percentile20.0',\n",
    "                  'jitterLocal_sma3nz_amean',\n",
    "                  'jitterLocal_sma3nz_stddevNorm',\n",
    "                 'F2bandwidth_sma3nz_stddevNorm',\n",
    "                 'spectralFluxV_sma3nz_amean',\n",
    "                 'spectralFlux_sma3_amean',\n",
    "                 'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope',\n",
    "                 'loudness_sma3_stddevRisingSlope',\n",
    "                 'slopeUV0-500_sma3nz_amean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2305be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that selects the most relevant columns and creates the target variable\n",
    "def import_and_clean (file_name, label):\n",
    "    df = pd.read_csv(file_name, sep='\\t')\n",
    "    df = df.loc[:,columns_to_keep]\n",
    "    df[\"target\"] = label\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd2f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement the function import_and_clean to the two dataframe (df_ASD and df_TD)\n",
    "df_ASD = import_and_clean(\"ASD_children.tsv\", \"ASD\")\n",
    "df_TD = import_and_clean(\"TD_children.tsv\", \"Controls\")\n",
    "\n",
    "#merge the 2 datasets\n",
    "df=pd.concat([df_ASD,df_TD],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e74e4d",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd54c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6f638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the function LabelEncoder to normalise the data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "df[\"target\"]=le.fit_transform(df['target'])\n",
    "df[\"target\"].tail()\n",
    "\n",
    "X = df[columns_to_keep]\n",
    "y = df[\"target\"]\n",
    "X = preprocessing.normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1809f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement the train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=.2, \n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dfa85d",
   "metadata": {},
   "source": [
    "## Supervised Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b736d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns;\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,confusion_matrix,mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainer (model_kind, n_splits=3, **args):\n",
    "\n",
    "    models = []\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle = True)\n",
    "\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        current = {}\n",
    "        Xfold_train = X_train[train_index,:]\n",
    "        Xfold_test = X_train[test_index,:]\n",
    "        yfold_train = y_train.iloc[train_index]\n",
    "        yfold_test = y_train.iloc[test_index]\n",
    "        # Create Logistic regression object\n",
    "        current[\"model\"] = model_kind(**args) #random_state=42\n",
    "        # Train the model using the training sets\n",
    "        current[\"model\"].fit(Xfold_train,yfold_train)\n",
    "        # Verify predictions using the training folds\n",
    "        y_pred = current[\"model\"].predict(Xfold_train)\n",
    "        current[\"train_accuracy\"]=current[\"model\"].score(Xfold_train, yfold_train) *100\n",
    "        #calculate the recall\n",
    "        current[\"train_recall\"]=recall_score(yfold_train,y_pred)*100\n",
    "        # calculate the precision\n",
    "        current[\"train_precision\"]=precision_score(yfold_train,y_pred)*100\n",
    "        # calculate the f1 score\n",
    "        current[\"train_f1\"]=f1_score(yfold_train,y_pred)*100\n",
    "        \n",
    "        # Verify predictions using the validation fold\n",
    "        y_pred = current[\"model\"].predict(Xfold_test)\n",
    "        current[\"val_accuracy\"]=current[\"model\"].score(Xfold_test, yfold_test) *100\n",
    "        #calculate the recall\n",
    "        current[\"val_recall\"]=recall_score(yfold_test,y_pred)*100\n",
    "        # calculate the precision\n",
    "        current[\"val_precision\"]=precision_score(yfold_test,y_pred)*100\n",
    "        # calculate the f1 score\n",
    "        current[\"val_f1\"]=f1_score(yfold_test,y_pred)*100\n",
    "\n",
    "        models.append(current)\n",
    "    models = pd.DataFrame(models)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ff937",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa0a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the classifier using model_trainer function \n",
    "#show the three folds obtained by the cross-validation on the train set\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_models = model_trainer(DecisionTreeClassifier)\n",
    "tree_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the best model between the three folds\n",
    "best_tree_model = tree_models.loc[1,\"model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decbea6b",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d6734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_models = model_trainer(KNeighborsClassifier)\n",
    "knn_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68e99bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn_model = knn_models.loc[2,\"model\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0ee006",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4112c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_models = model_trainer(RandomForestClassifier, max_depth=3, n_estimators=4)\n",
    "rf_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce4e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model = rf_models.loc[0,\"model\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debd02e4",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356c79bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm_models = model_trainer(LinearSVC)\n",
    "svm_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d10bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm_model = svm_models.loc[1,\"model\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752d56fe",
   "metadata": {},
   "source": [
    "### Calculate and Print the evaluation metrics for each model, both on tran and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d5523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL NAME and NUMBER OF RUNNING(NoR)\n",
    "\n",
    "y_train_model_NoR = best_model_NoR.predict(X_train)\n",
    "y_pred_model_NoR  = best_model_NoR.predict(X_test)\n",
    "\n",
    "#evaluate the performance of the train set\n",
    "\n",
    "#calculate the accuracy\n",
    "#train set\n",
    "model_NoR_train_accuracy=accuracy_score(y_train,y_train_model_NoR)\n",
    "print(\"Model accuracy of the model on train set: %.2f\" %model_NoR_train_accuracy)\n",
    "#test set\n",
    "model_NoR_test_accuracy=accuracy_score(y_test,y_pred_model_NoR)\n",
    "print(\"Model accuracy of the model on test set: %.2f\" %model_NoR_test_accuracy)\n",
    "\n",
    "#calculate the recall\n",
    "#train set\n",
    "model_NoR_train_recall=recall_score(y_train,y_train_model_NoR)\n",
    "print(\"Model recall of the model on train set: %.2f\" \n",
    "      %model_NoR_train_recall)\n",
    "#test set\n",
    "model_NoR_test_recall=recall_score(y_test,y_pred_model_NoR)\n",
    "print(\"Model recall of the model on test set: %.2f\" \n",
    "      %model_NoR_test_recall)\n",
    "\n",
    "# calculate precision\n",
    "#train set\n",
    "model_NoR_train_precision=precision_score(y_train,y_train_model_NoR)\n",
    "print(\"Model precision of the model on train set: %.2f\" \n",
    "      %model_NoR_train_precision)\n",
    "#test set\n",
    "model_NoR_test_precision=precision_score(y_test,y_pred_model_NoR)\n",
    "print(\"Model precision of the model on test set: %.2f\" \n",
    "      %model_NoR_test_precision)\n",
    "\n",
    "# calculate f1-score\n",
    "#train st\n",
    "model_train_f1=f1_score(y_train,y_train_model_NoR)\n",
    "print(\"Model F1-score of the model on train set: %.2f\" \n",
    "      %model_NoR_train_f1)\n",
    "#test set\n",
    "model_train_f1=f1_score(y_train,y_pred_model_NoR)\n",
    "print(\"Model F1-score of the model on test set: %.2f\" \n",
    "      %model_NoR_test_f1)\n",
    "\n",
    "# calculate AUC\n",
    "#train set\n",
    "model_NoR_train_AUC=roc_auc_score(y_train,y_train_model_NoR)\n",
    "print(\"Model AUC of the model on the train set: %.2f\" \n",
    "      %model_NoR_train_AUC)\n",
    "#test set\n",
    "model_NoR_test_AUC=roc_auc_score(y_train,y_pred_model_NoR)\n",
    "print(\"Model AUC of the model on the test set: %.2f\" \n",
    "      %model_NoR_test_AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50112e9",
   "metadata": {},
   "source": [
    "### Save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afabd1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "pickle.dump(tree_models, open(\"{}/decision_tree_clf.pkl\".format(directory), \n",
    "                              'wb'))\n",
    "pickle.dump(knn_models, open(\"{}/knn_clf.pkl\".format(directory), \n",
    "                             'wb'))\n",
    "pickle.dump(rf_models, open(\"{}/random_forest_clf.pkl\".format(directory), \n",
    "                            'wb'))\n",
    "pickle.dump(svm_models, open(\"{}/svc.pkl\".format(directory), \n",
    "                             'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8fd122",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ae4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_metrics_plot(y_test, y_preds):\n",
    "    cfm = confusion_metrics(y_test, y_preds)\n",
    "\n",
    "    tn = cfm[0][0]\n",
    "    tp = cfm[1][1]\n",
    "    fn = cfm[1][0]\n",
    "    fp = cfm[0][1]\n",
    "\n",
    "    group_names = ['True ASD','False TD','False ASD','True TD']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cfm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) \n",
    "                         for value in cfm.flatten()/np.sum(cfm)]\n",
    "    labels = [v1+'\\n'+v2+'\\n'+v3 \n",
    "              for v1, v2, v3 in zip(group_names,\n",
    "                                    group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "    sns.set(font_scale=1.3)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7,5)) \n",
    "    sns.heatmap(cfm, vmin = 0, vmax = 5, annot=labels, fmt='', \n",
    "                cmap='Blues', ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Gold standard labels', size=15)\n",
    "    plt.xlabel('Classifier output labels', size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb167c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement the function 'confusion_metrics_plot' to each best model, \n",
    "#both on train and test set\n",
    "\n",
    "confusion_matrix_plot(y_train,y_train_model_NoR)\n",
    "confusion_matrix_plot(y_test,y_pred_model_NoR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
