{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8698d65c",
   "metadata": {},
   "source": [
    "# Classification using Machine Learning Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e3130",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6266d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734b2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with only the columns of the selected features.\n",
    "# Here, we reported the features selected during our study as example.\n",
    "columns_to_keep= ['spectralFluxUV_sma3nz_amean', \n",
    "                  'shimmerLocaldB_sma3nz_stddevNorm',\n",
    "                  'HNRdBACF_sma3nz_amean',\n",
    "                  'shimmerLocaldB_sma3nz_amean',\n",
    "                  'HNRdBACF_sma3nz_stddevNorm',\n",
    "                  'slopeUV500-1500_sma3nz_amean',\n",
    "                  'F2frequency_sma3nz_stddevNorm',\n",
    "                  'loudness_sma3_percentile20.0',\n",
    "                  'jitterLocal_sma3nz_amean',\n",
    "                  'jitterLocal_sma3nz_stddevNorm',\n",
    "                 'F2bandwidth_sma3nz_stddevNorm',\n",
    "                 'spectralFluxV_sma3nz_amean',\n",
    "                 'spectralFlux_sma3_amean',\n",
    "                 'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope',\n",
    "                 'loudness_sma3_stddevRisingSlope',\n",
    "                 'slopeUV0-500_sma3nz_amean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ad01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that selects the most relevant columns and creates the target variable\n",
    "def import_and_clean (file_name, label):\n",
    "    df = pd.read_csv(file_name, sep='\\t')\n",
    "    df = df.loc[:,columns_to_keep]\n",
    "    df[\"target\"] = label\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f30178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the function import_and_clean to the two dataframe (df_group1 and df_group2)\n",
    "df_group1 = import_and_clean(\"group1.tsv\", \"group1\")\n",
    "df_group2 = import_and_clean(\"group2.tsv\", \"group2\")\n",
    "\n",
    "# Merge the 2 datasets\n",
    "df = pd.concat([df_group1, df_group2],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a0cf01",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ec376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function LabelEncoder to normalise the data\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "df[\"target\"] = le.fit_transform(df['target'])\n",
    "df[\"target\"].tail()\n",
    "\n",
    "X = df[columns_to_keep]\n",
    "y = df[\"target\"]\n",
    "X = preprocessing.normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c97fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, shuffle = True, random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5d36d6",
   "metadata": {},
   "source": [
    "## Supervised Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cad5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns;\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,confusion_matrix,mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainer (model_kind, n_splits = 3, **args):\n",
    "\n",
    "    models = []\n",
    "    skf = StratifiedKFold(n_splits = n_splits, shuffle = True)\n",
    "\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        current = {}\n",
    "        Xfold_train = X_train[train_index,:]\n",
    "        Xfold_test = X_train[test_index,:]\n",
    "        yfold_train = y_train.iloc[train_index]\n",
    "        yfold_test = y_train.iloc[test_index]\n",
    "        # Create Logistic regression object\n",
    "        current[\"model\"] = model_kind(**args)\n",
    "        # Train the model using the training sets\n",
    "        current[\"model\"].fit(Xfold_train,yfold_train)\n",
    "        # Verify predictions using the training folds\n",
    "        y_pred = current[\"model\"].predict(Xfold_train)\n",
    "        current[\"train_accuracy\"] = current[\"model\"].score(Xfold_train, yfold_train)*100\n",
    "        # Calculate the recall\n",
    "        current[\"train_recall\"] = recall_score(yfold_train,y_pred)*100\n",
    "        # Calculate the precision\n",
    "        current[\"train_precision\"] = precision_score(yfold_train,y_pred)*100\n",
    "        # Calculate the f1 score\n",
    "        current[\"train_f1\"] = f1_score(yfold_train,y_pred)*100\n",
    "        \n",
    "        # Verify predictions using the validation fold\n",
    "        y_pred = current[\"model\"].predict(Xfold_test)\n",
    "        current[\"val_accuracy\"] = current[\"model\"].score(Xfold_test, yfold_test)*100\n",
    "        # Calculate the recall\n",
    "        current[\"val_recall\"] = recall_score(yfold_test,y_pred)*100\n",
    "        # Calculate the precision\n",
    "        current[\"val_precision\"] = precision_score(yfold_test,y_pred)*100\n",
    "        # Calculate the f1 score\n",
    "        current[\"val_f1\"] = f1_score(yfold_test,y_pred)*100\n",
    "\n",
    "        models.append(current)\n",
    "    models = pd.DataFrame(models)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b3c8b6",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ae15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier using model_trainer function \n",
    "# Show the three folds obtained by the cross-validation on the train set\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_models = model_trainer(DecisionTreeClassifier)\n",
    "tree_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1507f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best model between the three folds\n",
    "best_tree_model = tree_models.loc[1,\"model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24826008",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539725ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_models = model_trainer(KNeighborsClassifier)\n",
    "knn_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5038cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn_model = knn_models.loc[2,\"model\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b044976",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_models = model_trainer(RandomForestClassifier, max_depth=3, n_estimators=4)\n",
    "rf_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05394677",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model = rf_models.loc[0,\"model\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c66eb6",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a6516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm_models = model_trainer(LinearSVC)\n",
    "svm_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e32b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm_model = svm_models.loc[1,\"model\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4e94c2",
   "metadata": {},
   "source": [
    "### Calculate and Print the evaluation metrics for each model, both on tran and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54481810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL NAME and NUMBER OF RUNNING(NoR)\n",
    "\n",
    "y_train_model_NoR = best_model_NoR.predict(X_train)\n",
    "y_pred_model_NoR = best_model_NoR.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the train set\n",
    "\n",
    "# Calculate the accuracy\n",
    "# Train set\n",
    "model_NoR_train_accuracy = accuracy_score(y_train,y_train_model_NoR)\n",
    "print(\"Model accuracy of the model on train set: %.2f\" %model_NoR_train_accuracy)\n",
    "# Test set\n",
    "model_NoR_test_accuracy = accuracy_score(y_test,y_pred_model_NoR)\n",
    "print(\"Model accuracy of the model on test set: %.2f\" %model_NoR_test_accuracy)\n",
    "\n",
    "# Calculate the recall\n",
    "# Train set\n",
    "model_NoR_train_recall = recall_score(y_train,y_train_model_NoR)\n",
    "print(\"Model recall of the model on train set: %.2f\" %model_NoR_train_recall)\n",
    "# Test set\n",
    "model_NoR_test_recall = recall_score(y_test,y_pred_model_NoR)\n",
    "print(\"Model recall of the model on test set: %.2f\" %model_NoR_test_recall)\n",
    "\n",
    "# Calculate precision\n",
    "# Train set\n",
    "model_NoR_train_precision = precision_score(y_train,y_train_model_NoR)\n",
    "print(\"Model precision of the model on train set: %.2f\" %model_NoR_train_precision)\n",
    "# Test set\n",
    "model_NoR_test_precision = precision_score(y_test,y_pred_model_NoR)\n",
    "print(\"Model precision of the model on test set: %.2f\" %model_NoR_test_precision)\n",
    "\n",
    "# Calculate f1-score\n",
    "#Train st\n",
    "model_train_f1 = f1_score(y_train,y_train_model_NoR)\n",
    "print(\"Model F1-score of the model on train set: %.2f\" %model_NoR_train_f1)\n",
    "# Test set\n",
    "model_train_f1 = f1_score(y_train,y_pred_model_NoR)\n",
    "print(\"Model F1-score of the model on test set: %.2f\" %model_NoR_test_f1)\n",
    "\n",
    "# Calculate AUC\n",
    "# Train set\n",
    "model_NoR_train_AUC = roc_auc_score(y_train,y_train_model_NoR)\n",
    "print(\"Model AUC of the model on the train set: %.2f\" %model_NoR_train_AUC)\n",
    "# Test set\n",
    "model_NoR_test_AUC = roc_auc_score(y_train,y_pred_model_NoR)\n",
    "print(\"Model AUC of the model on the test set: %.2f\" %model_NoR_test_AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512600b9",
   "metadata": {},
   "source": [
    "### Save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca748ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "pickle.dump(tree_models, open(\"{}/decision_tree_clf.pkl\".format(directory), 'wb'))\n",
    "pickle.dump(knn_models, open(\"{}/knn_clf.pkl\".format(directory),'wb'))\n",
    "pickle.dump(rf_models, open(\"{}/random_forest_clf.pkl\".format(directory), 'wb'))\n",
    "pickle.dump(svm_models, open(\"{}/svc.pkl\".format(directory),'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ecb45",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a60645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_plot(y_test, y_preds):\n",
    "    cfm = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "    tn = cfm[0][0]\n",
    "    tp = cfm[1][1]\n",
    "    fn = cfm[1][0]\n",
    "    fp = cfm[0][1]\n",
    "\n",
    "    group_names = ['True g1','False g2','False g1','True g2']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cfm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) \n",
    "                         for value in cfm.flatten()/np.sum(cfm)]\n",
    "    labels = [v1+'\\n'+v2+'\\n'+v3 \n",
    "              for v1, v2, v3 in zip(group_names, group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "    sns.set(font_scale=1.3)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7,5)) \n",
    "    sns.heatmap(cfm, vmin = 0, vmax = 5, annot=labels, fmt='', cmap='Blues', ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Gold standard labels', size=15)\n",
    "    plt.xlabel('Classifier output labels', size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d85dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the function 'confusion_metrics_plot' to each best model, both on train and test set\n",
    "confusion_matrix_plot(y_train,y_train_model_NoR)\n",
    "confusion_matrix_plot(y_test,y_pred_model_NoR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
